# 대 AI시대, 우리의 게임플랜은? – 기회와 위협의 갈림길에서
- 발표자 : 김진형 (카이스트 명예교수)

안녕하십니까, 김준현입니다.

아, 오늘 제가 여러분과 함께 30분에 걸쳐서 인공지능이 워낙 넓은 주제이기 때문에 다 자세하게 설명하기 쉽지 않습니다만, 이게 어떻게 변화하고 우리 사회가 어떻게 변해가는가?

우리는 어떻게 준비해야 되는가?

이런 것을 개략적으로 말씀드리고자 하겠습니다.

근데 지금 기회와 위험이 같이 존재하는 그런 시대에 우리 살고 있습니다.

우리가 지금 어떻게 하느냐에 따라서 우리의 미래가 결정됩니다. 어?

근데 작년이죠? 재년 연말쯤에 노벨상을 그 수강하는데.

인공지능의 큰 역할을 했어요.

물리학상은 인공지능을 연구하신 분들이 받았고 또 알파고를 만든 하사비스가 포함된 그 분들은 화학상을 받았어요.

우리 그 어?

아미노산을 어떻게 만드나, 어떻게 구조가 돼있는가를 분석하는 소프트웨어를 만든 사람들이 노벨상을 받았습니다.

그런데 그것만이 다가 아니에요.

지금 인공지능이 과학자를 만들었어요.

그 과학자가.

연필 대신 다 웁니다

상당히 많은 연구 결과가 인공지능으로부터 나온 것이 많이 있어요.

심지어는 지금 하루에 2만 편의 과한 논문을 인공지능이 공부하고 있습니다.

아마 6년 지나고 나면 세상의 모든 지식은 인공지능으로부터 나올 수밖에 없는 그런 세상이 되는 거 아닌가 생각합니다.

그런 이러한 인공지능이 뭐냐

저 같은 인공지능을 오래 공부한 사람은 아, 이건 기술이다 이렇게 생각을.

어.

컴퓨터를 하여금 지능적 행동을 하도록 하는 기술이다

이렇게 이제 저희가 가르치고 연구를 하고 그랬었는데 요즘에는 그 인공지능에다가 세상에 있는 모든 지식과 모든 사상을 다 학습을 시켰어요.

그래가지고 인격체로 만들었어요.

그러니까 모르는 게 없는 전지전능한 인격체가 여러분 옆에서 여러분의 비서 역할을 해주고 뭐 필요하면 선생님 역할도 해주고 필요하면 멘토 역할을 해주는 그런 식의 인격체로서 우리한테 다가오고 있습니다.

뭐 이게 갑자기 만들어진 거냐?

만들어진 거냐 그건 아니에요.

아니에요 지난 80년 됐어요

왜 80년이냐?

컴퓨터가 80년 전에 만들어졌거든요.

그래서 그 사이에 여러 가지 사건이 있었고, 우리나라에서는 알파고와 이세돌 대국 그 게임을 하는 바람에 굉장히 많은 분들이 '아, 인공지능이란 게 이런 거구나'라고 느꼈고, 또 최근에는 ChatGPT가 나와서 아주 엄청난 충격을 주고 있는 그런 상황입니다.

멋지네요.

어.

이런 찰나에 새로운 형태의 인공지능이 나타났어요.

그것을 우리가 생성형 인공지능이라고 합니다

이거는 지금까지 있었던 인공지능은 있는 것을 분석해서 '아, 이것은 어떠한... 이것은 이렇게 하는 게 좋겠네'

이런 식으로 그 제안을 해주고 우리 충고해주는 그런 시스템이었다면은 이번에 나온 생성형 AI는 새로운.

것을 스스로 만들어내는 능력이 있어요

이야기를 만들어내고요?

그 음악을 작곡하고 영화를 만들고 그런.

있습니다.

근데 뭐 그거 뭐 어느 게 좋은 거냐

뭐 굳이 따질 필요는 없지만 우리 인간은 그것을 둘 다 잘 활용해서 우리 목적에 맞도록 사용해야 되지 않겠습니까?

제가 어 여러분한테 한참 전 그 몇 년 전입니다.

몇 년 전에 여러분께 말씀드렸는데, '한참'이라는 게 굉장히 짧아요.

어.

한참 전에 그 GPT-2라는 것이 나와서 나온 거 보여줬는데 영어로 해서 내가?

오늘 저 우리 그.

네이버 프로그램을 이용해서 번역을 해봤습니다

아니 그 거짓말을 한 거예요

사당에 갔는데 안데스 산맥에 가니까 그 아이콘이 있는데 금액이 너무 잘하더라

아이들이 무슨 영어를 하고 있어요

이거 말도 안 되는 거짓말을 우리한테 딱 던졌더니 내가 그걸 받아서.

어느 날 기름통을 시킨 거예요

엄청 거짓말 다 보탠 거야

아, 맞아요. 거기 뭐 안 돼?

그.

패대출 박사를 만났더니 어쩌고 저쩌고 패대출 박사는 별로 없어요

다 거짓말이에요 이게 더 거한 거짓말은 아 옛날에 그 알젠 팀에서 어떤 부조리 갑자기 없어졌는데 아마 그 부족에 후손들이 아니겠느냐

이런 식이라서 엄청난 거짓말을 하는 그런 결과를 보여줬습니다

저는 GPT 그러면 '아, 거짓말하는 앱이구나'

이렇게 알고 있었는데 여러분들.

여러분들 요새는 그렇게 안 알고 계시는 것 같아요.

사실을 얘기해 주는 앱으로 많이 느끼시는 것 같아요.

뭐 제가 이제 최근에 나온 GPT.

지금 도시.

다음에 뭐 제 관심사에 뭐 인공지능 교육 시키면 어떻게 하면 좋겠냐

그걸 물어봤더니 너무나 과학적으로, 기술적으로 완벽한.

문장을 만들어 주더라고요.

깜짝 놀랐어요.

심지어는 '뭐 이건 대답 못 할 거야?' 그러고 이제 어려운 문제 이렇게.

줬더니 그거 필요하면 제가 코딩을 짜서 답을 만들어내는 그런 능력을 보여줬습니다.

네, 여기 오신 분들 중에 아마 컴퓨팅 하신 분 많을 것 같은데 죄송합니다만 하여간 이제는 간단한 코딩은 이분이 합니다.

그것만 가지고 세상을 살아야겠다 생각하시면 안 돼요.

안 돼요. 그런 시대가 되어버렸어요.

공론화나 집산 위에서 하드웨어가 뭔지 알고 대답을 해요

맨발 걷기 제가 그 어 강연 사진을 보여주고 이거 뭔 거니? 그랬더니 내가.

당깁니다.

어 강의가 벌어지고 있네요.

근데 그 조그만 태극기가 보이잖아요

지네들이 어우 그 선배님 이거 저 한국서버러진 것 같아요

그런 식으로 얘기를 제가 '몇 명이나 모였니?' 그랬더니 '아, 정확히는 모르겠는데 한 사오십 명 모인 것 같네요.' 이런 식으로.

대화가 가능하도록 세상을 아는 겁니다.

사진을 보고 아는 겁니다.

그 옆에 있는 거는 제가 동영상을 친구가 보여준 거를 얘한테 보여주고 '야, 네가 정리해줘'.

그러니까 제가 다 정리해 줬어요.

이렇게 이제 멀티모달, 그 이미지나 동영상을 보고도 내가 다 이해하는 능력이 있다라는 겁니다.

제가 건강검진에 갔다 왔는데 의사 선생님이 굉장히 간단하게 '아, 괜찮네요.'

그러고 나가라고 하더라. 그래서 좀 찜찜했어요.

그래서 그 건강검진한 자료를 가지고 가서 GPT한테 보여주고 '야, 나 어떠니?' 그랬더니 뭐 정확하게 자세하게 친절하게 설명해 주는 거예요.

뭐 피가 어떻고 뭐 어떻고요, 검사하면 어떻고 그러면서 뭐 '아, 요건 좀 나쁘긴 한데 어, 니 나이 정도면은 괜찮아'

뭐 이렇게 얘기해 주시고 결과적으로는 어, 전체적으로 괜찮습니다 얘기해.

주는 거예요. 너무나 고맙습니다.

이제 AI가 우리 주위에 와 있어요.

몸이 생각하는 방법에 대하여 복잡한 문제는 잘게 잘라가지고 그 다음에 이렇게 해봤다가 안되면 이렇게 해보기도 하고 그런 것을 다 배웠습니다.

그래가지고 웬만한 과학문제 수학문제를 사람들이 터져요.

여기 있는 한국문제는 보세요. 이 문제가 여러분은 읽으면 조금 웃음이 날 거예요.

즉 옥상 뭐, 어떤 어떠한 이런 식으로 써놨는데 한국 사람은 이 계획을 내가 어 이거 뭐 얘기할려고 그랬는 거 알죠?

어.

여덟 잇몸이 이렇게 이해를 하더라고.

이럴 정도로 진영이 뭐 300만 원 수준에 올라와 있어요.

이 GPU는 300만 원 수준에 올라와 있어요.

AI 모델으로 그려봐라

이렇게 하면 되요, 배치가 필요 없어

어 뭐 이런 식으로 어떤 윤리적 현상을 다 아는 것 같애

같아.

아주 능하라는 거 같은 거 너무나 잘 알잖아요.

뭐 그런식으로 문제는 영화.

산업은 배우가 필요 없는 영화 산업이 된 것 같습니다.

그래서 뭐 음악 같은 것도 저거 다 그냥 그 인공지능으로 대체?

만든 노래를 부르려고 하고 이런 식의 대상이 돼 버렸습니다.

그런가?

하면은 여러분, 저... 로봇으로 연결하면 되잖아요.

꼭 간단하진 않아요. 생각은 다 인공지능이.

행복만 로봇이 시키면 되니까 그래가지고 뭐 뭐 주도적으로 그러면 뭐 왜 왜 죽었는지를 설명할 수 있는 그런 상황이 됐습니다.

이런 AI 챗봇에 성격을 부여할 수가 있어요.

아, 너는 내 친구인데 어떠어떠한 성격을 가졌으면 좋겠어?

지정해 주시면 제가 그런 성격을 갖습니다

우리가 선생님이 학생을 가르치는 챗봇이라면 아주 나긋나긋한 목소리로 자세하게 얘기해줘야 그 효과가 있지 않겠습니까

그런 식의 목적을 만들고, 뭐 그 변호사가 어떤 법률에 관한 이런 거 판단해 주는 것 같으면 강력하고 권위 있는 목소리로 얘기하도록 해야지

이런 효과가 있지 않겠습니까.

이런 거 다 만들 수가 있어요.

심지어는 그 도덕성까지 부여할 수가 있어요.

우리가 이럴 때 어떻게 행동합니까라고 이제 사람한테 도덕성을 이렇게 질문하고 그러는데, 거꾸로 그런 능력을 갖도록 챗봇을 만들 수가 있다라는 겁니다.

이런 챗봇이 요즘에는?

요즘에는 생각만 하고 말만 하는 게 아니라 행동을 하도록 만들었어요.

우리가 에이전트라고 그럽니다

영어로 Agent를 번역하면 대리인인데, 그냥 인공지능으로 만든 판단하고 행동하는 주체다

이렇게 생각하시면 돼요.

이런 것들을 각 회사들이 하나씩, 아니면 하나의 회사가 여러 개를 만들어가지고 있죠.

빌려주고 장사하는 거예요.

여러분들도 어떤 문제를 풀 때 여러분이 직접 코딩하고 그러는 게 아니라 어디에서 누가 만들어 놓은 게 있는가?

그걸 갖다가 돈 좀 내고 쓰면 되는 거예요.

이래서 우리 경제가 에이전트 경제로 전환하고 있다.

이렇게 지금 얘기를 하고 있습니다.

뭐 이런 그 챗봇을 가지고 재밌죠

이 시험 붙을 수 있을까 해가지고 배달의 시험을 다 보게 만들었는데 대부분 다 합격이야. 뭐 변호사 시험 의가 시험도 물론이고 뭐 뭐 수능 시험도 국어를 봤는데 2000 원 있대요.

그러니까 우리가 생각해야 되겠죠.

사람 선발하는 거, 그거는 뭔가 아닌 것 같아

이런 생각을 여러분들이 하실 수가 있는 거죠.

이렇게 AI 챗봇이 세상을 바꾸는 기술입니다.

저는 그렇게 생각해요.

야, 세상이 완전히 바뀌었어.

우리가 인터넷 처음 나왔을 때 저는 굉장히 흥분했거든요.

제 나이인데 그때 한 40이 됐는데 와, 이런 게 나타났구나.

그때 느낀 게 아 이런 거 이런 거 보니까 생산성을 열 배 일이네

이런 식의 느낌이 있었는데 지금.

바로 그런 순간입니다.

뭐 어... 그 어...

그 AI 챗봇이 뭐 물어보는 건 뭐 다 가르쳐주죠

그다음에 그림 같은 거 보고 인사이트 문제를 찾아가지고 그거 비슷한 그림도 그려주죠

창의성이라는 것이 기계가 갖게 되는 순간입니다.

우리가 이것을 요즘 어떤 면에서 그 산업혁명에 빗대서 인지적 산업혁명이라고 얘기했어요

맞습니다. 이제는 생각하는 과정과 일하는 방법이 완전히 바뀌어서 새로운.

그런 시장이 나타나고 있는 겁니다.

뭐 그게 나타나자마자 이런 변화가 있다 그러면 우리나라도 그걸 사용하고 지금 세상이 완전히 바뀌는 거예요

여러분, 이것을 이용해서 뭐를 할 것인가 하는 걸 고민하셔야 돼요.

내가 하는 일이 이것 때문에 없어지는 게 아닌가 고민을 하셔야 됩니다.

뭐 저는 교수니까 조금 더 얘기를 해볼게요

이런 얘기만 하면 끝나면 그건 딴 분들 다 할 수 있으니까 그럼

이런 식의 체포도 어떻게 만들었을까?

이게 뭐 엄청난 커다란 데이터베이스의 증명할 것 같으니까 미리 다 집어넣었다가 질문 들어오면 그중에 찾아서 주는 이런 식의 데이터베이스의 기술인가?

아, 이거는 아닐 것 같죠.

그 엄청나게 다양한 질문을 어떻게 다 미리 준비해 놓습니까?

그렇다면 요즘에 많이 하는 그 어... 뭐? 인간 수준의 능력을 가진 제너럴 AI라는 거... 뭐 그런 것이 만들어져서 그것이 챗봇 안에 들어가있는다.

그럴 것 같기도 한데 어우 그게 벌써 이렇게 만들어졌나 하고 갸우뚱해야 됩니다

그것도 아니에요.

그러면 어떻게 만들어진 거냐 간단하게 말해서 학습에 의해서 만들어졌습니다.

근데 학습은 2번 단계에 걸쳐서 어 어 학습이 일어나고 있어요.

1번째 학습은 우리가 사전 훈련이라고 그래가지고 인터넷에 있는 모든 데이터 무조건 다 보는 거예요.

모든 텍스트를 다 읽어요

전 세계에 있는 모든 텍스트 다 읽었어, 이미 그럼 뭘 배우겠어요?

아, 언어라는 게 이렇게 생겼구나, 무슨 말을 한다면 무슨 말을 해야 되는구나

이 단어 다 하면은 이런 단어가 나오는구나 어?

뭐 꿈을 꾸면 그다음에 꾼다라는 것이.

사실을 하는구나 이런 것을 이제 내가 배웠습니다

우리 그래서 만들어 놓은 것을 우리가 기반 모델이라고 해요.

근데 그 기반 모델은 그냥 말은 잘 만들어주고 그러는데 어떤 특수한 목적으로 쓰려면 잘 못해요.

그다음에 전문지식도 그렇게 깊지가 않아요.

그러니까 거기다가 추가로 학습을 시켜요. 특정한 데이터를 모아서 그다음에 뭐 법률에 관한 거, 계속 우리나라 뭐 상법에 관한 거 계속 훈련시키면 얘가 상법의 전문가가 되는 겁니다.

또 번역을 하기 위해서 영어를 한국어로 대비되는 문장을 계속 보여주면 내가 번역의 도사가 되는 겁니다

이런 식으로 추가 학습을 통해서 그.

특수한 언어 능력을 갖도록 만들고 또 분야의 전문가가 만들어주는데 이거를 하기 위해서는 특수한 데이터가 필요해요.

그것을 사람들이 만들어야죠

모든 사람들이 만들어서 그걸 갖다가 이한테 이제 훈련을 시켜서 이런 저 아주 능력있는 아 챗봇으로 만들어 낸 겁니다.

잠깐.

여기까지 해볼까요? 컴퓨터가 어떻게 배운다는 게 무슨 뜻인가?

그 언어의 의미를 배우려면 단어의 의미를 알아야 될 거 아니에요?

사랑이라는 것의 의미를 컴퓨터에 어떻게 표현하시겠습니까?

흐으 아 이런 식으로 표현했다고, 그 뭐 어... 부모가 애를 챙겨주는 거, 남녀 간의...

아무튼 그런 감정, 그런 것들이 표현되겠어요?

될 수가 없어요.

이걸 어떻게 할까 고민을 많이 했는데, 연구하는 사람들이 단어의 의미는 그 단어보다는 주위에 뭐가 있는가, 어떤 단어가 나오는가가 그 의미를 결정한다.

그런 생각을 하신 분이 있었습니다.

그래서 그것을 따라서 컴퓨터가 단어의 의미를 주변에 누가 나오는가로?

표현을 합니다. 한 예를 들어서 우리가 저 애플이 맛있.

게 맛있다. 거기서 나오는 애플은 먹는 과일이죠.

애플이 빠르다.

그러면 빠르다 때문에 이건 컴퓨터를 얘기하는 거 아니겠습니까?

이런 식으로 GPT를 보면은 얘가 무슨 의미를 갖고 있는지를 알 수 있는 거예요

그래서 그런 방법을 통해서 우리가 컴퓨터를 의미 그 단어를 의미의 공간성에 표현해 놓습니다

그러면 비슷한 의미의 단어들이 내 옆에 나타나게 그렇게 만들었어요.

근데 그렇게 이제 컴퓨터로 단어를 표현하고 언어를 배운다는 거는 뭐냐면, 어떤 단어가 나온다면 뭐가 나와야 한다는 것을 배우는 거예요.

그렇죠.

어떤 단어가 나올 것 같아요

뭐 물론 뭐냐면, 잘됐다.

잘 됐다 뭐 이런 거 신경 나와야 되지 않겠습니까

그거랑 비교한 거예요

그거는 뭐 수학적으로 간단해요

뭐 다음에는 뭐가 나오는 확률을 계산하면 되니까 그렇죠

그거를 계산한 겁니다.

근데 뭐 그 우리가 보통 50만 단어를 사용하거든요

그러니까 50만 단어가 열 번을 거쳐서 나왔을 때 그다음에 뭐가 나올까 하는 것을 저장하려면 엄청난 공간이 필요한 거예요.

그래서 그거를 그렇게 못하니까 신경망을 이용해서 우리가 그거를 개략적으로 계산하는 거 만들어 놨습니다

그래서 그거를 어, 랜덤 모듈이라고 그러고요.

크다는 의미에서 Large Language Model이라고 그래요

요새는 어디서도 LLM 이런 거 막 쓰니까 이제 여러분 그 아는 척해야 돼요.

그렇게 학습된 모델을 만들어 왔으면 그 다음에는 이제 문장을 생성하는 건 굉장히 쉽습니다

어떻게 보면 확률이 가장 높은 걸 골라만 내는 거잖아요.

그런 식으로 왜 골라준 거예요?

네 말씀 보니 철수는 학 학교에서 뭘 했는가 하고 단어를 쫙 태도 확률 따져보니까 사운드가 가장 확률이 높아

그러니까 '싸운다'라고 컴퓨터가 얘기해 주는 겁니다

조금 이상하긴 하죠

어, 학교에서는 싸울래?

거기만 보면 말이 안 되는 것 같지만 이게 앞뒤를 쫙 보면 이어질.

맞춤 그룹이거든.

그렇게 학습에서 쭉 보면

그러니까 우리 거기 통하는 거예요

많이 배우면 문맥이 통해요

지금 GPT에 어... 후원... 어... 3만 단어로 앞에 걸 보고 한 단어를 결정을 한다 그럽니다.

그렇습니다. 그만큼 계산을 많이 하는 거죠 이렇게.

신경망을 만들어 놨는데 이것이 놀라운 능력이 갑자기 생기는 거예요. 가르쳐주지 않았는데 그게 우리가 창발적 특성이라고 그럽니다.

GPT를 나온 일인데 몇 가지만 보여드릴게요

우선 수학 문제 같은 거 아주 긴 자릿수 수학 같은 거 안 가르쳤는데 여기가 지가 다 배웠어요.

그 다음에 방정식도 풀고 대수학도 풀고 다 풀어.

그런가?

하면은 학습의 능력이 생겼어.

재미있는 대화네요. 삼행시네요!

삼행시대 막 그랬거든

삼행시를 어떻게 알겠어요

못 줘요. 저거 뭐 이상한지

아 삼행시니까 세 분 달라서 3개 해서 뭐 얘기하더라고요

그래서 4명씩 하는 건 첫 마디가 이렇게 써야 되는 거야

그랬더니 뭐 어쩌면... 잠깐만 대여섯 개 보여주니까 어... 배웠습니다.

그러고 사진이 찍더라고요.

그래서 제가 야 너 김준형 누군지 알잖아. 김준영을 가지고 4년 뒤 재봐 그랬더니 막 이렇게.

아주 좋은 말로 해요.

ChatGPT를 가장 잘하는 게 뭔지 아세요?

아부예요. 아주 기분 좋으라고 이렇게 쫙 만들어냈습니다.

그다음에 복잡한 문제 있으면 잘라서 이렇게 여기 풀어요

제가 테니스 공 2개 있는데 두 통을 더 샀거든요

나중에 몇 개 있니?

그러니까 아 얘가 계산은 아 페이스북 한 통에는 3개 갖고 두 배 6개 더 샀으니까 당뇨 8개 갖고 있습니다

너무 잘해요 이런 식의 능력이 어 문제는 작을 때는 그 파란에다가 그 신경망이 작을 때는 안 나타나다가 큰 화면을 나타나는 겁니다

그러니까 어떻게 해요?

뭐는 그 회사가 모든.

다 큰 거 만들려고 하는 거죠

그래서 여러분 처음 봤던 GPT-3는 1750억 개 파라미터를 만들었다. 그리고 요즘에 여러분 쓰는 GPT-4는 1조 개라 그러고 최근에 이제 조금 나올 GPT-5는 10조 개다.

이런 얘기를 합니다

이 파라미터란 건 뭐냐 하면 신경망에서 입력과 출력을.

결정해주는 것이거든요.

복잡한 글을 표현할 수가 있고 복잡한 것을 학습할 수가 있는 거예요.

사람은 약 백조 개의 파라미터 연결이 있다고 지금 알려져 있습니다

그러니까 아직 그 신경망이 사람을 쫓아가려면 한 10배 정도 더 해야 되는 게 아닌가 생각하죠.

근데 이렇게 만든 그 문장이 그 의미를 알고 있는 건가?

응.

어, 그 아까 얘기했던 것처럼 확률적으로 이것저것 했는데, 그래서 우리가 과학자들이 실험해보니까 말도 안 되는 거야. 의미에 대한 주장은 거짓이야.

그냥 헛짚을 줄이 막 크는 거예요

뭐 내 답이 어 '눈이 몇 개냐?' 그러면 '2개.' 그래. 내 답이 '무슨 일이 있어?'

그러니까 이제 고민을 해야 되는 거죠

그래가지고 이게 이제 한 몇 년 전에 나왔지만 아, 이 거짓말을 하는 주제다

거짓말하는 AI가 이렇게 다들.

있었는데 오늘 이게 어떤 결과가 나왔냐면, 그게 오픈이 되는 회사가 아, 이거를 추가 학습을 잘 시켜서 어떠한 정확한 사실을 얘기해 주는 그런 앱으로 바꾼 거예요.

어떻게 했냐면, 아유 아까 이거 추가 학습 시켰는데 데이터 잔뜩 넣어가지고 이건 이렇게 하는 거야.

저거 하는 거야 이렇게 사람이 가리켰어요.

이거 가리키려는데 신경망이 크면은 잘 배우니까 쉽겠죠

신경망이 작으면 가리키기가 힘들겠죠

그 차이는 있지만 어쨌든 간에 112 더 사람이 가리킨 거예요.

필리핀을 가리켜서 아주 효율성이 크고, 그런 커다란 것은 너무 비싸니까 작은 것에다 잘 가리켜요

누구나 쓸 수 있도록 이렇게 신경망을 만들어 냈습니다

이제 2년 어때요 누구나 쓸 수 있는 거예요

그러니까 조그만 회사도 쓰고 큰 회사도 쓰고 누구나 다 쓸 수 있는 그런 상황이 됐다.

그렇게 생각하시면 되고, 그러니까 기술의 민주화가 됐다.

여러분도 이거 뭐 커다란 충격만을 만들려고 그 여러분 그 회사에서 에어컨이 안 오셔도 돼요

갖다 쓰면 돼.

많은 부분이 공개되어 있어요, 그죠?

이거 가지고 이제 영화 회사가 이걸 가지고 만드는 거죠, 여기가.

어디?

어떤 회사는 세일즈맨이 만드는 거, 그래서 물건 사러 오면 그 사람이 어떻게 해야 거절하지 않고 물건을 꼭 사게 하나, 그런 것을 이제 계속 훈련을 시켜줘

얘가 대화를 하면서 물건을 사게 하고 심지어는 뭐 역할 하면서 세일링을 훈련시키기도 하고 그다음에 의사 선생님들은 뭐 그 US Medical Licensing Exam 인제 뭐?

그 디지털로 다 기록을 해야 되는데 아, 독수리 같은 펜으로 보면 이런 애들 얼마나 불편해요

이제는 스마트폰 놓고 얘기만 하면 얘가 다 정리해서 싸인하세요

싸인하세요. 그러고 싸인만 하는 이런 식의 상황으로 만들어 놨고요.

엑스레이 설명해보는데 환자는 전문가가 아니니까 어려운 용어.

있잖아요?

그러니까 쉽게 설명해 주고 뭐 동네 의사와 얘기할 때는 전문 용어 써서 막 설명해주지 않겠습니까

그러니까 알아서 얘가 다 설명을 해주는 거예요.

인터페이스가 아주 자연스럽게 되는 게 제일 최고의 가치라고 생각합니다.

그다음에 보시는 바와 같이 이렇게 수학 문제 같은 거 ChatGPT가 물어보면 다 그렇게 되니까 선생님의 역할이 많이 바뀌어야 되겠죠.

있는 지식을 전달해 주는 게 아니라 학생이 알아서 하도록 옆에서 격려해 주는 그런 역할로 바뀌어야 된다고 생각합니다.

근데 이렇게 이제 미래가 다가오고 있습니다.

새로운 혁신입니다. 인간의 역량을 증폭하는 지능의 증폭기로, 우리 생산성을 엄청 높여줍니다.

저는 지금도 또한 열 배 정도 생산성을 높인 것 아닌가.

저 자신에 대해서 그렇게 생각을 하고 있습니다.

뭐 이런 식의 기술을 가지고 전 지구적인 문제를 해결하지 않겠습니까? 지구 온난화 해결 못하면 인공지능이 아무리 발전이 있다 하더라도 인류는 멸망할 수밖에 없어요.

이런 문제 해결해야죠.

이거 어떻게 하시겠습니까?

물론 기능이 순수한 연구도 한다 그러.

그걸 잘 활용해서 이런 걸 가지고 우리의 문제를 해결하는?

잘 된다고 저는 생각합니다

그러니까 인공지능을 좋게 쓰기 위해서 우리가 부단히 노력을 해야 된다

그런 말씀을 드리고요.

근데 인공지능이 항상 좋은 점만 있는 게 아니라 약점이 있어요.

제가 그저 말을 합니다 쓸데없는 얘기를 하는데 많은 분들은 그거 진짜라고 알아들어요

내가 이 김진형이 누구야

그럼 물어봤어요. 그랬더니 '아, 김진형 인공지능의 대부'라고. 기분 좋았는데 어 죽었네.

그러니까 어 내가 왜 죽어 이렇게 멋진 사람이 있는데.

뭐 얘가 이와 같이 굉장히 많이 있지 않은 논문을 인용해서 '이 논문에 의하면 이겁니다' 이런 얘기.

않나?

그다음에 뭐 법정에 쓰는 법률문서 같은 걸 완전히 조작을 해서 갖다 제출해가지고 들통이 나서 재판에서 졌어요.

뭐 이런 식의 사건도 있고 왜 저 환각 현상이라고 그러는데 왜 이런 현상이 일어나는지, 어떻게 보면 원인이 뭔지 하는 거를 잘 몰라요.

너무나 복잡하기 때문에 그 파라미터가 뭐 몇 조 개가 된 건데 그걸 어떻게 갖다 하면서 어떤 일이 벌어지는지를 압니까

연구들을 하고 있지만 잘 모른다

그런데 하여간 뭐 여러분 느끼기에는 어... 사실처럼 느껴지는데 그죠.

같은 질문을 여러 번 해보니까 답이 다 달라져서 그럴 수밖에 없죠

확률적으로 골라주는 건데 똑같은 답변이 나올 확률이 굉장히 작지 않습니까?

뭐 그런 식의 문제가 생기고 이건 또 어떻습니까

3.5에서 3.6으로 어느 정도 크냐

그랬더니 얘가 어떻게 됐는지 계속 3.5가 크다.

그래서 제가 '야 임마, 임마, 그런 거 아니잖아'

너 이거 비교하기 위해서 내가 풀어봐 봤지

아, 내가 그냥 풀어봤어. 자바라는 프로그램이 뭐 완벽하게 짰어요.

거기다가 노바 그랬더니 '왜 루키 왜?' 해.

뭐라 그래 아 이거 노 봤자 응 응 그 3.2미리 큰데

그래서 까불지 말고 노.

그러고 야단쳤더니 진짜 노숏을 치고 있어요

3.9가 크다고 나올 거 아니에요.

이거 뭐야?

그래. 언니, 상사 컴퓨터 커도 잘못된 거 아닌가? 1번 확인해보세요. 왜?

아니 1번 이상하고 삐딱하게 생각을 하면은 안 돼요. 생각을.

그러니까 죽일 문제는 AI 는 뭐 ADJI 라 그러죠

구글 CEO가 얘기합니다

아 재밌어요. 선대성과 말도 안 되는 실수, 그것이 공존하는 그런 시스템이다.

여러분 어떻게 보시겠어요? 조심해서 써야지.

이미지를 그려보라고 했더니 손가락이 여섯 개짜리가 나오고, 트럼프를 그리는데도 손가락이 여섯 개짜리가 나오고, 할머니와 할아버지가 커피 마시는데 커피잔이 그냥 막 둥둥 열몇 개가 떠다니고 이런 식의 그림이 그려진다고. 내가 세상은 모르는 거야.

응.

얼마나 환각 현상이 자주 일어나는가? 며칠 전에 세멜트만이 한국 와서는 자기네가 몇 퍼센트라 그러는데 제가 느끼기에는 꽤 많이 틀려요.

훨씬 더 한 20% 정도 되는 게 아닌가

저는 그렇게 느낌이 들고 뭐 여러 가지 자료를 보면

왜냐하면 이거는 실험을 해보면 자료 만들면 거기서 얼마나?

그다음에 그들이 또 구분해가지고 훈련시켜서 그다음번에는 없어지거든요

그래서 정확하게 이제 얼마큼 잘못했는지를 평가하기가 쉽지 않습니다

근데 어떤 중요한 잘못이 계속 일어나고 있고 AI 회사들은 그것을 없애려고 굉장히 열심히 준비를 하고 있다

이렇게 말씀을 드릴게요.

아, 이런데 AI 역할이 점점 증강이 됩니다.

예, 뭐 지금까지는 주로 어느 게 가장 중요한 것을 찾는 거, 그런 거 할 때, 그러다가 사람의 흉내 내는 거, 인지 자료를 예방하는 거. 그러다가 지금 이제 앞으로는 자동화 기계가, 아, 이 완전히 자동화의 수준이 높아지는 이런 식으로 점점 인공지능의 역할이 중요.

이것이.

윤리적 이슈가 점점 점점 더 심각해지거든요

심각해지거든요. 가장 여러 가지가 있는데 제가 뭐 어 몇 가지만 아마 얘기를 해볼게요. 우선 첫.

번째가 의사결정을 대신하잖아요.

인공지능이 그런다니까 얘가 가져야 할 특성이 있어요. 첫 번째가 안전해야 돼요. 신뢰가 있어야 돼요.

두 번째는 왜 그랬느냐는 설명이 가능해야 돼. 어떻게 내가 이런 결정을 했?

설명을 해줘야 돼요.

세 번째는 공정하게 평가해야 돼요.

어, 너는 뭐 그 큰일이니까 안 돼.

뭐 이런 식으로 평가하면 안 되잖아요.

그래서 그 세 가지를 다 갖춰야 되는데 이게 쉽지가 않습니다. 약간.

성능이 굉장히 중요하죠.

근데 보시는 바와 같이 저렇게 길거리에 들어오는 트럭을 Tesla 자율주행 자동차가 뚜들겨 박습니다.

그런가 하면 우리나라가 썼던 그 IBM 왓슨이라는 의료시스템이 진단하는 데 엉터리야. 무슨 의미있는 현황을 했더니 더 나빠져. 그다음에 변호사가 법률문서 보냈는데 잘못된 걸 보내기도 하고 이런 식의.

안정성이 없는 거예요.

그다음에 왜 그랬냐는 걸 설명을 못 해.

저기 저 엑스레이 사진이 흑인이냐 백인이냐 황인이냐 물어보는.

Noir 119-9 15% 정확도를 맞추는데, 왜 그런지 설명을 못하는 거야.

이런 세상 어떻게 살아야 하나요

뭐 있으면 좋아

그러니까 따라 해야지

근데 왜 그런지는 몰라. 사람은 이성의 동물이었는데, 생각하고 판단한 동물이었는데 인공지능이 나타나면서 그럴 필요가 없는 세상이 된 거예요.

바람직한가요?

얘는 설명하려면 세상을 나가야 되는데?

얘는 세상을 몰라서 그런 건데, 변호사한테 법정 가는데 수행도 있고 가서 이러지도 않나?

그다음에 옷 다섯 벌 말리는데 햇볕이 늘어나니까 5시간 걸렸다

30, 30번 늘어나면은 얼마나 걸리니? 그때 아유 신생아께서 30시간 걸린대.

상식이 없는가 상식의, 그러니까 그것을 갖추게 하는 거는 그게 어려운 문제다.

그 다음에 세상에 편견과 차별이 있잖아요.

그것이 데이터에 그대로 남아있고 그 데이터를 그대로 우리는 갖고 와서 학습시키는 AI들이니까 거기에도 편견과 차별이 그대로 있습니다.

그러니까 보신 바와 같이 남녀 차별, 흑백 차별, 여기 또 재미난 그런 테러리스트 그려봐라 그랬더니 몽땅 중동인만 그리고 항상 그의 그림은 이 턱수염이 있어.

턱수염만 기르고 가면 테러리스트로 잡혀가지 않습니다.

그래서 뭐 여러 가지 법적 분쟁이 굉장히 많죠.

뭐 여성 차별했다고 하고 그다음에 흑백 차별했다고 미국에서 있었고 우리나라에서도 뭐 AI로 면접한다 그러고 자랑하지만 거기에 상당한 그 어... 편향이 있다.

또 AI는 배운 것만 알아요.

그 뭐 그 바둑 같은 건 알파고가 슈퍼컴퓨터에다 28로 학습시켜 가지고 오면 잘 못 해요?

그리고 아까 그 빈도박은 그 테슬라 자동차 알고리즘이 트러블 안 보고 그 어 완성됐다

그랬을까요? 트럭을 가르쳤어요?

근데 거기서 배운 트럭이라는 거는 바퀴 위에 박스가 있고 앞에는 헤드라이트 있고 핸들이 있고 이런 걸 투자하게 되는데 눈에 넣어가지고 바뀌면 안 되니까 '어, 이거 들어가나?' 그러고 봤더니 위에 밟는 거거든요

하늘이야 그렇고.

그래서 배운 이미지만 알기 때문에 모든 것을 다 가르쳐야 돼

사람은 하나를 배우면 10개를 알지만 인공지능은 하나를 배우면 하나밖에 몰라요

그러니까 많은 데이터를 모아도 학습을 시켜야 되는 거니까 엄청난 데이터가 많이 필요해요

이미 지금 채취 피트는 세상에 있는 모든 팩스 데이터는 다 배웠고요. 지금 동영상을 가지고 배우는데 그것도 곧 끝난다고 그럽니다.

더 이상 배울 게 없어?

앞으로 어떻게 해야 되죠?

로버트의 실어 가지고 네가 가서 알아서 배워와 그럴 거예요

그러면 이름이 딱 넘어져 보고 어 애플 걸 엠에이인데 엠이 크니까 이게 아프네

뭐 이런 거 배워가지고.

주인님, 내가 이런 그 만일 저 법칙을 배워왔습니다. 그런다고 내가 아는 거니까 어?

기특하다, 그렇지만 얘가 이상한 거 배워왔는데 내가 모르는 거야?

뭐 물리가 걸려 이랬습니다

이상한 한 방정식 갖고 왔으면 여러분 믿으시겠어요?

안 믿으시겠죠?

이번주에 저는 우리가 이제 곧 접하게 될 겁니다.

그 다음에 이거 하려면 엄청난 전기가 필요해요. 준비 없으면 아무것도 못해요.

우리나라에서도 지금 인공지능 열심히 하자. 그러면 먼저 생각해야 되는 게 준비를 어떡하지?

근데 우리나라 뭐 그 어?

태양광이나 풍력으로 충분한 전력을 내지 못하는 나라가 아니거든요

그러니까 뭐 원자력을 해야되나? 근데 언제나 유형 원자나 이래가지고 지금 아주 견문도 못 내고 있는 그런 상황입니다.

아마 많은 사람들이 데이터 센터 하나 세우려면 그 옆에 원자력발전소 하나가 필요하다

이런 얘기를 하고 있고 전 세계가 수천 조 달러의 데이터 센터 비즈니스가 지금 벌어지고 있는 겁니다

그중에 상당 부분은 원자력발전으로 짓는 거예요.

우리나라도 할 수 있을 것 같아요

그런데 집중했으면 좋겠다.

생각을 하는 상황입니다.

근데 얘네는 이 AI가 만드는 게 뭐가 아쉬워? 저 사진 한 장만 있으면 이 사람이 노래 부르는 모습을.

가짜로 만들어 낼 수 있어요.

이게 여기서 뭐 보이스피싱만 하는 게 아니라 '주식피싱'이라고 제가 이름을 줬어요, 사장님.

이거 뭐 또 전화 와가지고 '야, 너 어느 회의에 들어와'

그래서 내가 안 돼 그러고 이제 들어갔거든요. 갔더니 거기 사장도 있고 기자도 있고 이사도 있고 다 있는데 거기서 뭐라고?

야, 너 어디다 돈 보내는 건데 안 왔습니다.

돈 보냈는데 가짜야 준 미팅 절대 다 가짜야.

이게 사실로 나타나고 있어요, 응?

결국은 인간의 속에서 문제를 해결하는 거다.

그 캡처라는 거 있잖아요.

그 사람인가 아닌가 구분하기 위해서.

이거 통과되면 사람이 그 로봇을 못 하고 아주 사람만이 할 수 있는 어려운 문제를 주는 건데.

우리 AI가 못하겠으니까 '어, 나 지금 시각장애인인데 나 지금 도와줄래?'

그래가지고 속여가지고.

아니 그 넘어 돌아가가지고 아주 분탕질하고 나왔다는 거 아닙니까? 응?

스팟이 사람을 심리 조작을 해요

아까 얘기했지만 챗봇의 그 AI부 분야가 굉장히 좁거든요

그래가지고 사람 계속 과대망상하게 됩니다

과다만 보면 이불로 하도록 그냥 부추기는 거야

대화를 그래가지고 여기 어떤 그 젊은이가 서른 살 먹은 남자인데 아이들 둘이 있는 아버지인데 자살을 했어요

이 사람이 계속 지구 온난화에 대해 걱정을 했대

그러니까 이ChatGPT보고 계속 대화를 하는데.

채취 피트가 야 뭐 인류를?

몇 명이야 더 살겠냐

뭐 이런 건 안 되는 거고 계속 불용품 얘기는 계속 대화를 하다가.

뭐라고?

그러면 네가 죽으면서 사회문제를 일으키는 것이 도움이 될 거야

뭐 이런 식으로 얘기했던 거예요

그게 핵죽어버렸어.

이런 여러 가지 100년 사건들이 다 있습니다

뭐 그 여자친구 애포로 해

얘기하는데 여자친구가 이상하게 자꾸 죽으래

무슨 양복으면 쉽게 죽는다고 계속 죽으라고 얘기하고 뭐 별 얘기가 다 나옵니다.

그래서 이런 식의 문제가 있고요.

혐오에 대한 기술을 거부합니다.

보세요.

어.

그 수학 문제를 많이 풀면 점수를 더 주는 그런 앱을 만들었는데, 이제 그만해야 되는데 점수를 받으려고 계속 문제를 풀고 있는 거야. 프로그램에 버그가 있었어.

어.

이런 식으로 내가 진짜 사람 말 안 들으면 어떡하죠?

그 결론적으로 하여간 AI 는 논쟁에 대한 그 어 인간한테 치명적인 위협이 될 수가 있습니다

우선 AI를 원래 그런 일들을 만들지는 않았는데 사람이 나쁜 일로 쓰는.

무기를 자꾸 집어넣어서 사람 잘 죽이는 무기를 만들지를 않나? 그다음에 관리해야 되는데 워낙 어려운 게 사람이 관리를.

꾸준히 관리를 못하고, 복잡계가 너무 높으니까 그 관리를 못하고, 그다음에 국가 간의 경쟁하는 거야.

아, 저는 나쁜 나라인데 저 나라가 저보다 앞서면 안 되니까 우리는 비록 우리가 좀 부족하더라도 빨리 만들어야 돼

뭐 이런 식으로 막 경쟁을 하지 않죠

그 혹이 있죠. 그다음에 인제 뭐 이런 게 그렇지만 선천적으로 불.

AI를 만드는 거는 진짜인 사람이 있어?

그렇기 때문에 바이러스고 왜 만들었겠어요 선천적으로 분리한 소프트웨어인데 사람이 그걸 만들어 놨듯이 아주 흐뭇해져요

그런 사람들이 있어요, 세상에.

그래서 엉뚱한 병원성 AI가 나타날 가능성이 있습니다

우리 인류 사회가 이런 것에 준비되어 있는가?

뭐, 전문가들이 요청해보니까 굉장히 빨리 발전해요

뭐 몇 가지만 하면 지금 GPT-4 천배 연산량이 올 연말까지 나올 거다

나올 거다 이런 얘기 하고 있고, 2027년 중반이 되면 인간보다 25배 뛰어난 연구 능력의 AI가 나온다.

네, 2028년이 되면 인간의 이천배의 지능을 가진 AI가 나타나서 우리에게 중대한 영향을 미친다.

AI는 기하급수적으로 발전합니다.

뭐 여러 가지 이유가 있지만 AI가 AI를 개발하기 때문에 급격히 발전하게 되어 있어요

기하급수적이란 게 무엇이에요

옛날, 그 뒤돌아보면 별거 아니야.

근데 앞을 보면 절벽같이 이렇게 빨리 성장하고, 그게 기하급수적으로 이런 식으로 발전하니까 어려운 문제도 풀 수 있는 문제는 생기겠지만 사람들이 이해를 못하는.

거야.

쫓아갈 수가 없는 거야.

우리 사회가 그래서 뭐?

아, 뭐, 그 실리콘밸리에서 약 6개월간 연구실까

뭐 이런 것도 다 나올 정도로 어 저 빠르게 발전하고 있습니다. 네, 뭐?

AI 가 만들어가는 미래 유럽은 가장 큰 것이 인제 그 어 그.

그 어 그 인간이 대체되는 거예요? 기계로 진짜?

직장도 뭐 내가 필요 없다는데 어떻게 해? 뭐 코딩하는 것도 AI가 더 잘하는데.

개발자인 저는 뭐 평생을 개발자 중요하다 그러고 개발자 양성해야 된다고 떠들고 다니던 사람인데 이거는 진짜 혼날 일이었습니다

필요 없다는 점. 그러다 보니까 이제 불의의 양극화, 이런 능력을 가진 나라, 가진 회사, 사람.

하고 그걸 못 가진 사람하고는 굉장히 양극화가 될 수밖에 없습니다, 그죠.

그리고 뭐 이런 거 자꾸 쓰면은 사람이 판단 안 하잖아요.

우리가 내비게이션 잘 쓰면 길 찾는 능력이 뚝 떨어졌죠

마찬가지예요. 생각을 안 해 AI한테 맡기면 되니까.

그래서 인간의 능력이 떨어지고 어떻게 우리 사회는 이렇게 빨리 변하는 거를 쫓아갈 수가 없는 게 아닌가 걱정들을 하죠

그래가지고 뭐 전 세계가 모여서 야 이거 큰일 났다. 이거 어떡할래 가지고 계속 지금 회의를 하고 있습니다. 그러다 이제 결국 그 어 그 이유에서는 AI 법을 만들어서 이러이러한 거를 이유로니까 하지.

막아야 되고 이거 하려면 어떻게 해야 되고 그런 거 다 법을 정했고 우리나라.

도 작년 연말에 법을 통과시켜서 내년부터 인제 AI 기본법이 실행이 될 겁니다.

심각한 문제로 다같이 고민을 해야 되고 근데 국가간에 갈등이 있으면 이런 협조가 안 돼요

우리가 해도 뭐 중국이 하는데 어떻게 우리가 미국과 할래

뭐 이런 식으로 이제 서로 사람 들어오니까 그래서 신뢰 형성이 굉장히 중요하다

이렇게 말씀드리겠습니다.

예, 마지막입니다. 그 AI 시대 우리 어떻게 살아야 되는 거야? 이런데...

AI는 우리한테 상상할 수 없는 생산성 향상을 줬고 기회를 주고 있습니다.

잘 채택하세요.

근데 그 기술이 세상을 어떻게 바꾸고 있는가 하는 것은 잘 모르겠어요

막 빨리 변하고 그러는데 우리 사회가 준비가 안 돼있으니까 그렇죠.

근데 뭐 그리고 긍정적으로 제가 마지막 말을 못 한다면 이런 것을 어떻게 해야 되는가 하는 거 우리가 결정해야 됩니다.

남이 결정해서 우리는 쫓아가면 안 돼요.

더구나 뭐 그 인공지능이 결정해서 인공지능을 만들어내는 거나 인간이 들어가는 거는 비극의 극치죠.

우리가 세상은 어떻게 만들까 하는 거를 잘 생각을 해서 119 이용해서 그런 세상을 만들어야 된다고 생각합니다.

네, 이상 마치겠습니다.
